{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1916b63-503c-4b13-8a55-7279c20f6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['negative' 'neutral' 'positive']\n",
      "Shape: (14617, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv('cleaned_tweets.csv')\n",
    "df = df.dropna(subset=['clean_text'])\n",
    "df = df[df['clean_text'].str.strip() != '']\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['airline_sentiment'])\n",
    "\n",
    "print(\"Classes:\", le.classes_)\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb71a1d5-fd3e-443d-9c4b-01c5d6437751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11693\n",
      "Test size:  2924\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_text'].values,\n",
    "    df['label'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6da42e3-057a-4490-960c-0fb90edce103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenization done!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(texts, max_len=64):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(X_train)\n",
    "test_encodings = tokenize(X_test)\n",
    "\n",
    "print(\"✅ Tokenization done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aef84c1-152e-4153-9de1-1c2abf1155e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset ready!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, y_train)\n",
    "test_dataset = SentimentDataset(test_encodings, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "print(\"✅ Dataset ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01be3e07-dc52-4877-ba8b-ed2aa135ab2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032722f2d9d1422ea99db7f7f0bc8824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cpu\n",
      "✅ BERT model loaded!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"✅ Using device:\", device)\n",
    "print(\"✅ BERT model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e027d-c4a5-45df-b585-a30a030b125f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 731/731 [10:50<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Avg Loss: 0.5756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  16%|█████████████████████▍                                                                                                                  | 115/731 [01:44<09:55,  1.03it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} — Avg Loss: {round(avg_loss, 4)}\")\n",
    "\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452be772-2046-4da0-8b0a-beaa86004d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 183/183 [00:32<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ BERT Accuracy: 80.88%\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.91      0.88      1857\n",
      "     neutral       0.71      0.56      0.62       625\n",
      "    positive       0.73      0.72      0.72       442\n",
      "\n",
      "    accuracy                           0.81      2924\n",
      "   macro avg       0.76      0.73      0.74      2924\n",
      "weighted avg       0.80      0.81      0.80      2924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        preds = outputs.logits.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "acc = accuracy_score(y_test, all_preds)\n",
    "print(f\"\\n✅ BERT Accuracy: {round(acc * 100, 2)}%\")\n",
    "print(\"\\n\", classification_report(y_test, all_preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d346a4f2-851d-410a-98f2-6b5a9b4c1f61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m         pred = outputs.logits.argmax(dim=\u001b[32m1\u001b[39m).item()\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m le.classes_[pred]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthe flight staff was horrible and they were unwelcoming\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(predict_bert(\u001b[33m\"\u001b[39m\u001b[33mAbsolutely loved the flight experience!\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(predict_bert(\u001b[33m\"\u001b[39m\u001b[33mLost my luggage and no one helped me\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mpredict_bert\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_bert\u001b[39m(text):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmodel\u001b[49m.eval()\n\u001b[32m      3\u001b[39m     inputs = tokenizer(\n\u001b[32m      4\u001b[39m         text,\n\u001b[32m      5\u001b[39m         return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m         truncation=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      9\u001b[39m     ).to(device)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_bert(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        max_length=64,\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        pred = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "    return le.classes_[pred]\n",
    "print(predict_bert(\"the flight staff was horrible and they were unwelcoming\"))\n",
    "print(predict_bert(\"Absolutely loved the flight experience!\"))\n",
    "print(predict_bert(\"Lost my luggage and no one helped me\"))\n",
    "print(predict_bert(\"The flight was on time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cade72bc-cb9e-477d-a2f6-436732e3eaa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m.save_pretrained(\u001b[33m'\u001b[39m\u001b[33m./saved_bert_model\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m tokenizer.save_pretrained(\u001b[33m'\u001b[39m\u001b[33m./saved_bert_model\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m le_classes = le.classes_\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./saved_bert_model')\n",
    "tokenizer.save_pretrained('./saved_bert_model')\n",
    "le_classes = le.classes_\n",
    "import numpy as np\n",
    "np.save('./saved_bert_model/le_classes.npy', le_classes)\n",
    "print(\"✅ Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852e858-dba9-4ab5-9845-4f4d13f636b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
